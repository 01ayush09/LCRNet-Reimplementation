{"cells":[{"cell_type":"markdown","id":"ff4f800e-217a-4fa6-8a54-616965b99b04","metadata":{"id":"ff4f800e-217a-4fa6-8a54-616965b99b04"},"source":["Project Overview: This notebook is designed to analyze crime data from Los Angeles, covering the period from 2020 to the present day. By leveraging exploratory data analysis (EDA) and machine learning techniques, we aim to discover trends, identify patterns, and develop a predictive model to enhance our understanding of crime occurrences in the area."]},{"cell_type":"markdown","id":"fc98c5b2-7f65-49e7-930c-2dba34a62d1e","metadata":{"id":"fc98c5b2-7f65-49e7-930c-2dba34a62d1e"},"source":["Data Description\n","DR_NO: Unique identifier for each record.\n","Date Rptd: Date the crime was reported.\n","DATE OCC: Date the crime occurred.\n","TIME OCC: Time the crime occurred.\n","AREA: Area code or ID where the crime took place.\n","AREA NAME: Name of the area where the crime took place.\n","Rpt Dist No: Reporting district number.\n","Part 1-2: Type of crime classification\n","Crm Cd: Crime code, a numeric code representing a specific crime.\n","Crm Cd Desc: Description of the crime code\n","Mocodes: Modus operandi codes, which might describe crime methods or patterns.\n","Vict Age: Age of the victim.\n","Vict Sex: Gender of the victim.\n","Vict Descent: Descent or ethnicity of the victim.\n","Premis Cd: Code for the type of premises where the crime occurred.\n","Premis Desc: Description of the type of premises\n","Weapon Used Cd: Code for the weapon used in the crime.\n","Weapon Desc: Description of the weapon used\n","Status: Status code, possibly indicating the case status.\n","Status Desc: Description of the status code\n","Crm Cd 1 to Crm Cd 4: Additional crime codes, potentially for incidents involving multiple crimes.\n","LOCATION General location information, possibly an address or landmark.\n","Cross Street: Cross street or intersection near the incident.\n","LAT: Latitude of the crime location.\n","LON: Longitude of the crime location."]},{"cell_type":"code","execution_count":null,"id":"3e168267-2134-4d85-91fd-6eb065f50bd3","metadata":{"id":"3e168267-2134-4d85-91fd-6eb065f50bd3"},"outputs":[],"source":["'''Installing and Importing necessary libraries\n","'''"]},{"cell_type":"code","execution_count":null,"id":"17a5eac5-0b7e-4cc5-b9ee-385d3416b57a","metadata":{"id":"17a5eac5-0b7e-4cc5-b9ee-385d3416b57a"},"outputs":[],"source":["# Libraries to help with reading and manipulating data\n","import numpy as np\n","import pandas as pd\n","import time\n","\n","# Libraries to help with data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()\n","\n","# Removes the limit for the number of displayed columns\n","pd.set_option(\"display.max_columns\", None)\n","# Sets the limit for the number of displayed rows\n","pd.set_option(\"display.max_rows\", 200)\n","\n","# to split the data into train and test\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# To build model for prediction\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree\n","\n","# To get diferent metric scores\n","from sklearn.metrics import (\n","    f1_score,\n","    accuracy_score,\n","    recall_score,\n","    precision_score,\n","    confusion_matrix,\n",")\n","\n","\n","\n","import tensorflow as tf #An end-to-end open source machine learning platform\n","from tensorflow import keras  # High-level neural networks API for deep learning.\n","from keras import backend   # Abstraction layer for neural network backend engines.\n","from keras.models import Sequential  # Model for building NN sequentially.\n","from keras.layers import Dense\n","\n","# to suppress warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"id":"eLy9pzqZF0s3","metadata":{"id":"eLy9pzqZF0s3"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"c91b12e0-5e68-4bf7-b697-9de533d0ddba","metadata":{"id":"c91b12e0-5e68-4bf7-b697-9de533d0ddba"},"source":["Loading the dataset"]},{"cell_type":"code","execution_count":null,"id":"b2b96cef-d9fd-4317-b983-b6be2976be10","metadata":{"id":"b2b96cef-d9fd-4317-b983-b6be2976be10"},"outputs":[],"source":["data = pd.read_csv(\"/content/drive/My Drive/Machine_Learning/Crime_Data_from_2020_to_Present.csv\")"]},{"cell_type":"markdown","id":"46a7c9fe-1286-40d5-bc36-02c63bae0521","metadata":{"id":"46a7c9fe-1286-40d5-bc36-02c63bae0521"},"source":["Data Overview [Showing some samples of data]"]},{"cell_type":"markdown","id":"381f6a69-daf6-4350-b0b1-d898b7cd2f7d","metadata":{"id":"381f6a69-daf6-4350-b0b1-d898b7cd2f7d"},"source":["data.head(20).T"]},{"cell_type":"code","execution_count":null,"id":"66d16255-bb1c-44a2-aa39-8102edf033ee","metadata":{"id":"66d16255-bb1c-44a2-aa39-8102edf033ee"},"outputs":[],"source":["data.tail()"]},{"cell_type":"markdown","id":"9be9a19a-7fc6-4c5a-89f2-1931d67d0775","metadata":{"id":"9be9a19a-7fc6-4c5a-89f2-1931d67d0775"},"source":["Checking the shape of the data"]},{"cell_type":"code","execution_count":null,"id":"e2009a92-f028-48de-a6ab-4e0ca0fff8f4","metadata":{"id":"e2009a92-f028-48de-a6ab-4e0ca0fff8f4"},"outputs":[],"source":["data.shape"]},{"cell_type":"markdown","id":"c56f5c6e-b0e5-4e8a-a234-8a873fd171f3","metadata":{"id":"c56f5c6e-b0e5-4e8a-a234-8a873fd171f3"},"source":["There are 990293 rows and 28 columns. [Also satisfying the project criteria]"]},{"cell_type":"markdown","id":"df3684bb-0f2d-4906-9e6e-da6e2dc936ac","metadata":{"id":"df3684bb-0f2d-4906-9e6e-da6e2dc936ac"},"source":["Checking 10 random rows of the dataset"]},{"cell_type":"code","execution_count":null,"id":"96d9bea2-e3ca-4855-98dc-74e18598a933","metadata":{"id":"96d9bea2-e3ca-4855-98dc-74e18598a933"},"outputs":[],"source":["# let's view a sample of the data\n","data.sample(n=10, random_state=1)"]},{"cell_type":"code","execution_count":null,"id":"b1d03833-7487-4a67-8af8-19bb813dbe2c","metadata":{"id":"b1d03833-7487-4a67-8af8-19bb813dbe2c"},"outputs":[],"source":["# let's create a copy of the data to avoid any changes to original data\n","df = data.copy()"]},{"cell_type":"markdown","id":"c28e84ac-807a-4ea0-81d5-ef2a52d41063","metadata":{"id":"c28e84ac-807a-4ea0-81d5-ef2a52d41063"},"source":["Checking the data types of the columns for the dataset"]},{"cell_type":"code","execution_count":null,"id":"6fbc326d-5b2e-4107-9fe5-95f07a7e05ce","metadata":{"id":"6fbc326d-5b2e-4107-9fe5-95f07a7e05ce"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","id":"3ed1d15e-aa78-411a-8b95-0d510ca0dc61","metadata":{"id":"3ed1d15e-aa78-411a-8b95-0d510ca0dc61"},"source":["The dataset consists of 28 columns with varying data types, capturing a broad array of information about crime incidents. The data types range from integers and floats to objects (strings)"]},{"cell_type":"markdown","id":"f8cf7841-14ce-4d6a-bc55-00d5621ca26b","metadata":{"id":"f8cf7841-14ce-4d6a-bc55-00d5621ca26b"},"source":["Checking for duplicate values"]},{"cell_type":"code","execution_count":null,"id":"d36b2102-8e23-4409-8fcb-0298e3f40e4a","metadata":{"id":"d36b2102-8e23-4409-8fcb-0298e3f40e4a"},"outputs":[],"source":["# checking for duplicate values\n","df.duplicated().sum()"]},{"cell_type":"markdown","id":"774ca44b-7ea7-4ff3-af7c-1cbb538cc93e","metadata":{"id":"774ca44b-7ea7-4ff3-af7c-1cbb538cc93e"},"source":["Checking for missing values"]},{"cell_type":"code","execution_count":null,"id":"b3f5629c-9e91-4f7e-b893-f057125d8205","metadata":{"id":"b3f5629c-9e91-4f7e-b893-f057125d8205"},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"markdown","id":"d920ba70-3038-465b-8247-b32eed435f4e","metadata":{"id":"d920ba70-3038-465b-8247-b32eed435f4e"},"source":["Cols as Mocodes,vict sex, cross street etc has many missing values. We have to preprocess the missing values to create model for performing several needed prediction.\n","We will drop additional crime codes from Crm cd 1 to Crm cd 4 as they are not serving any purpose. We will also drop Cross street as it has many null values and when we already have LAT and LON we don't need it."]},{"cell_type":"markdown","id":"602637ed-6e23-41ae-a212-e39a73db9d8b","metadata":{"id":"602637ed-6e23-41ae-a212-e39a73db9d8b"},"source":["checking the statistical summary of the datset"]},{"cell_type":"code","execution_count":null,"id":"a41b353c-8d8c-44a9-9dbc-466852b032ce","metadata":{"id":"a41b353c-8d8c-44a9-9dbc-466852b032ce"},"outputs":[],"source":["df.describe().T"]},{"cell_type":"markdown","id":"116ee498-8dec-4468-b724-adb8346f2a50","metadata":{"id":"116ee498-8dec-4468-b724-adb8346f2a50"},"source":["DR_NO ranges from 817 to 2,499,289; TIME OCC from 1 to 2359; AREA from 1 to 21; Rpt Dist No from 101 to 2199; Vict Age from -40 to 120; Premis Cd from 0 to 976; Weapon Used Cd from 101 to 516; LAT from 33.4 to 34.3; LON from -118.3 to -118.2."]},{"cell_type":"markdown","id":"5226b877-1e23-4b56-b90f-8917287ee627","metadata":{"id":"5226b877-1e23-4b56-b90f-8917287ee627"},"source":["Exploratory Data Analysis (EDA) Summary"]},{"cell_type":"code","execution_count":null,"id":"202b8430-bfde-4b90-82c6-0246199574cb","metadata":{"id":"202b8430-bfde-4b90-82c6-0246199574cb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Defining the figure size\n","plt.figure(figsize=(22, 14))\n","\n","# Selecting only numerical columns for plotting\n","numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n","\n","# Plotting the histogram for each numerical feature\n","for i, feature in enumerate(numerical_features):\n","    plt.subplot((len(numerical_features) + 2) // 3, 3, i + 1)  # Adjusting subplot grid dynamically\n","    sns.histplot(data=df, x=feature, kde=True)  # Plotting the histogram with KDE for better visualization\n","    plt.title(f'Histogram of {feature}')  # Adding title to each subplot\n","\n","plt.tight_layout()  # Adding spacing between plots\n","plt.show()\n"]},{"cell_type":"markdown","id":"da8dec52-313a-4153-8b1a-159b8b985f42","metadata":{"id":"da8dec52-313a-4153-8b1a-159b8b985f42"},"source":["As we can see from the dataset,  \n","\n","TIME OCC = Most of the time occured There are noticeable peaks at certain times (e.g., around 400, 1200, and between 1800-2300), suggesting that crimes occur more frequently during these specific times. This could indicate higher crime activity during late evening and night hours. The sharp peak close to zero might represent crimes occurring very early in the morning or could indicate issues with data entry if 0 is not a valid time.\n","Overall, this histogram indicates that crimes are more likely to occur in the late afternoon, evening, and night, which could inform decisions on allocating resources during high-risk times.\n","\n","\n","Area = There are distinct peaks at certain area codes (e.g., around 2, 5, 12), indicating these areas have a higher frequency of reported crimes compared to others. This histogram helps identify high-activity crime zones, allowing for better resource allocation and focused crime prevention efforts in specific areas.\n","\n","Rpt Dist No  = The distribution of Rpt Dist No shows varying crime frequencies across districts. Some districts have noticeable peaks, indicating higher crime reports, while others show relatively low counts. This suggests specific districts have more reported incidents, which may require targeted attention.\n","\n","Part 1-2 = The Part 1-2 column shows a bimodal distribution with values clustered at 1 and 2, indicating two main crime classifications (likely \"Part 1\" and \"Part 2\" crimes). The frequency of \"Part 1\" crimes is significantly higher, suggesting these are more commonly reported incidents.\n","\n","Crm CD = Certain crime codes, such as those around 400 and 600, appear much more frequently, indicating these types of crimes are reported at a higher rate. Other codes have significantly lower frequencies, suggesting they represent less common crimes. This distribution highlights the prevalence of specific crime types in the dataset.\n","\n","Vict Age: The histogram for Vict Age shows a high concentration of values around the younger age group, with a few outliers at higher ages. There's an unusual peak at 0, which could represent missing or unknown age data.\n","\n","Premis Cd: The Premis Cd distribution is heavily skewed, with specific codes occurring far more frequently than others, indicating that certain premises are more common locations for incidents.\n","\n","Weapon Used Cd: Similar to Premis Cd, this histogram shows that a few weapon codes appear frequently, suggesting that certain types of weapons are more commonly involved in crimes.\n","\n","Crm Cd 1: The histogram for Crm Cd 1 shows multiple peaks, indicating a variety of primary crime codes with some codes significantly more frequent, suggesting common types of primary crimes.\n","\n","Crm Cd 2: The distribution of Crm Cd 2 is skewed towards higher values, with a sharp increase near 1000. This could indicate secondary crime codes being used selectively or for specific types of incidents.\n","\n","Crm Cd 3: Crm Cd 3 is similar to Crm Cd 2, with fewer data points but showing an increase near 1000, indicating that this code might only be applicable to specific cases.\n","\n","Crm Cd 4: The Crm Cd 4 histogram shows very few entries, with values concentrated near 1000, implying that this column is rarely used and may be relevant only for specific multi-offense incidents.\n","\n","LAT (Latitude): The latitude values are tightly clustered around a narrow range, which is expected as the data likely represents incidents within a specific geographical area.\n","\n","LON (Longitude): Similar to LAT, longitude values are concentrated within a limited range, reflecting the confined geographic scope of the dataset.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"540172d8-ed0e-4dec-ac54-c4f99b4b31d5","metadata":{"id":"540172d8-ed0e-4dec-ac54-c4f99b4b31d5"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Defining the figure size\n","plt.figure(figsize=(16, 14))\n","\n","# Selecting only numerical columns for plotting\n","features = df.select_dtypes(include=['number']).columns.tolist()\n","\n","# Creating the boxplots\n","for i, feature in enumerate(features):\n","    plt.subplot((len(features) + 2) // 3, 3, i + 1)  # Adjusting subplot grid dynamically\n","    sns.boxplot(data=df, x=feature)  # Plotting the boxplot\n","    plt.title(f'Boxplot of {feature}')  # Adding title to each subplot\n","\n","plt.tight_layout()  # Adding spacing between plots\n","plt.show()\n"]},{"cell_type":"markdown","id":"46a0068d-d369-48de-8d90-e37e17c044bf","metadata":{"id":"46a0068d-d369-48de-8d90-e37e17c044bf"},"source":["DR_NO: A few outliers on the lower end, though this column likely represents a unique identifier, so outliers here may not be relevant.\n","\n","TIME OCC: No visible outliers, as most times appear to fall within a consistent range.\n","\n","AREA: No significant outliers, as the data is evenly distributed within the range.\n","\n","Rpt Dist No: No clear outliers; the values are within a reasonable spread.\n","\n","Part 1-2: No outliers, with data concentrated at two distinct values, likely indicating two main categories.\n","\n","Crm Cd: No major outliers; the distribution of crime codes is within a standard range.\n","\n","Vict Age: Outliers are present on both the lower end (0) and higher end (above 100), which may represent errors or unusual cases.\n","\n","Premis Cd: No significant outliers, with values mostly within a reasonable range.\n","\n","Weapon Used Cd: Outliers appear on the lower end, likely due to specific weapon codes that occur less frequently.\n","\n","Crm Cd 1, Crm Cd 2, Crm Cd 3: Numerous outliers across these columns, especially in Crm Cd 2 and Crm Cd 3, where certain codes appear far outside the main cluster. These could represent unique crime codes that are less common.\n","\n","Crm Cd 4: Few outliers on the lower end, likely due to rare multi-crime codes.\n","\n","LAT and LON: Outliers are present on both latitude (LAT) and longitude (LON), indicating a few locations outside the main geographical area of the dataset."]},{"cell_type":"code","execution_count":null,"id":"40c6e2b6-0609-4b9d-a23f-680c7d597fe7","metadata":{"id":"40c6e2b6-0609-4b9d-a23f-680c7d597fe7"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Sample 10% of the data for faster plotting\n","sample_df = df.sample(frac=0.1, random_state=42)\n","\n","# Select only categorical columns with less than 50 unique values\n","categorical_features = [col for col in sample_df.select_dtypes(include=['object']).columns if sample_df[col].nunique() < 50]\n","\n","# Cap rare categories to \"Other\" for features with more than 10 categories\n","for feature in categorical_features:\n","    top_categories = sample_df[feature].value_counts().nlargest(10).index  # Top 10 categories\n","    sample_df[feature] = sample_df[feature].apply(lambda x: x if x in top_categories else 'Other')\n","\n","# Plotting bar plots for the selected categorical features\n","plt.figure(figsize=(16, 14))\n","\n","for i, feature in enumerate(categorical_features):\n","    plt.subplot((len(categorical_features) + 2) // 3, 3, i + 1)  # Adjusting subplot grid dynamically\n","    sns.countplot(data=sample_df, x=feature)  # Plotting the bar plot\n","    plt.title(f'Bar Plot of {feature}')  # Adding title to each subplot\n","    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n","\n","plt.tight_layout()  # Adding spacing between plots\n","plt.show()\n"]},{"cell_type":"markdown","id":"957476d8-8c7e-4daf-87f7-9ea49d3cefd4","metadata":{"id":"957476d8-8c7e-4daf-87f7-9ea49d3cefd4"},"source":["AREA NAME: The category \"Other\" has the highest count, followed by smaller, relatively even counts across other areas, indicating a concentration in unspecified areas.\n","\n","Vict Sex: Females (F) and Males (M) have the highest counts, with a small portion in \"Other\" and unknown categories, showing a typical gender distribution.\n","\n","Vict Descent: The majority of victims are in categories H and W, with a few other descent categories also appearing frequently, indicating a demographic pattern.\n","\n","Status: The IC status code dominates, suggesting that a majority of cases fall under this category, with other status codes being significantly less common.\n","\n","Status Desc: The majority of cases are categorized as \"Invest Cont,\" with fewer cases in other status descriptions, reflecting the primary status of reported incidents."]},{"cell_type":"markdown","id":"517cd9a4-f63e-4ac2-9c41-23839a260b5a","metadata":{"id":"517cd9a4-f63e-4ac2-9c41-23839a260b5a"},"source":["Bivariate Analysis"]},{"cell_type":"code","execution_count":null,"id":"0860e78b-78f0-4736-942a-ec1bcc4763f1","metadata":{"id":"0860e78b-78f0-4736-942a-ec1bcc4763f1"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Selecting only numerical columns for correlation\n","numeric_df = df.select_dtypes(include=['number'])\n","\n","# Defining the size of the plot\n","plt.figure(figsize=(12, 7))\n","\n","# Plotting the heatmap for correlation\n","sns.heatmap(\n","    numeric_df.corr(),  # Use only numeric columns for correlation\n","    annot=True,  # Annotate each cell with the numeric value\n","    vmin=-1, vmax=1,  # Set color scale limits to show full correlation range\n","    fmt=\".2f\",  # Format the annotations to two decimal places\n","    cmap=\"Spectral\"  # Color map for visual effect\n",")\n","\n","plt.title(\"Correlation Heatmap\")  # Adding a title for clarity\n","plt.show()\n"]},{"cell_type":"markdown","id":"6644daad-2d7f-4875-93c3-4f47f8bd5a36","metadata":{"id":"6644daad-2d7f-4875-93c3-4f47f8bd5a36"},"source":["The heatmap reveals a strong correlation between Crm Cd and Crm Cd 1 (0.70), indicating a close relationship between primary crime codes. Weapon Used Cd and Crm Cd also show a moderate correlation (0.37), suggesting specific weapons are common in certain crime types. Latitude (LAT) and Longitude (LON) have a perfect negative correlation (-1.00), as expected for fixed geographic points. Most other correlations are weak or near zero, showing minimal relationships between the remaining features."]},{"cell_type":"code","execution_count":null,"id":"58f9f7b0-2a5b-4d1b-92e2-147a9bd7b689","metadata":{"id":"58f9f7b0-2a5b-4d1b-92e2-147a9bd7b689"},"outputs":[],"source":["import seaborn as sns\n","\n","# Sample a fraction of the data to speed up the plotting\n","sample_df = df.sample(frac=0.1, random_state=42)  # Adjust fraction as needed (e.g., 0.05 for larger datasets)\n","\n","# Selecting a subset of columns for the pairplot\n","selected_columns = ['TIME OCC', 'AREA', 'Vict Age', 'Premis Cd', 'Weapon Used Cd', 'LAT', 'LON']\n","sample_df = sample_df[selected_columns]\n","\n","# Plotting the pairplot\n","sns.pairplot(sample_df)\n"]},{"cell_type":"markdown","id":"c98ad262-b663-4107-9d92-b1a8a36a5d66","metadata":{"id":"c98ad262-b663-4107-9d92-b1a8a36a5d66"},"source":["The pairplot shows the relationships between selected numerical variables in the dataset. TIME OCC appears uniformly distributed, with no clear patterns between crime times and area or premises types, indicating crimes occur across various times and locations. Vict Age shows a concentration of younger victims, distributed across a range of premises, suggesting that incidents involving younger individuals happen in diverse settings. LAT and LON values are tightly clustered, reflecting the dataset’s localized geographic scope with limited spread. Overall, the plot reveals minimal strong linear correlations among most variables.\n"]},{"cell_type":"code","execution_count":null,"id":"289a56a5-6eda-487b-aeb1-bd3112b86cc0","metadata":{"id":"289a56a5-6eda-487b-aeb1-bd3112b86cc0"},"outputs":[],"source":["#Data Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"6e541816-a1f8-46ac-906c-2f58d9b1212c","metadata":{"id":"6e541816-a1f8-46ac-906c-2f58d9b1212c"},"outputs":[],"source":["import numpy as np\n","\n","# Drop columns with excessive missing values (e.g., Crm Cd 2, Crm Cd 3, and Cross Street) in a single step\n","df = df.drop(columns=['Cross Street','Crm Cd 1', 'Crm Cd 2','Crm Cd 3','Crm Cd 4'])\n","\n","# Impute missing values in categorical columns with 'Unknown' or 'Other' using a single operation for each column\n","categorical_cols = ['Vict Sex', 'Vict Descent', 'Weapon Desc', 'Premis Desc']\n","df[categorical_cols] = df[categorical_cols].fillna('Unknown')\n","\n","# For numerical columns with missing values, use vectorized operations for mean or median imputation\n","# Apply conditions in one step for Vict Age\n","df['Vict Age'] = np.where((df['Vict Age'] > 0) & (df['Vict Age'] <= 100), df['Vict Age'], df['Vict Age'].median())\n","\n","# Use median imputation for other numerical columns\n","numerical_cols = ['Weapon Used Cd', 'Premis Cd']\n","for col in numerical_cols:\n","    df[col].fillna(df[col].median(), inplace=True)\n"]},{"cell_type":"code","execution_count":null,"id":"5f49bf6c-2028-468b-a7bf-a1a7266bf491","metadata":{"id":"5f49bf6c-2028-468b-a7bf-a1a7266bf491"},"outputs":[],"source":["# Fill missing values in 'Mocodes' with 'Unknown' as it might contain categorical information\n","df['Mocodes'].fillna('Unknown', inplace=True)\n"]},{"cell_type":"code","execution_count":null,"id":"117fb710-de75-4de7-b101-db7f63248407","metadata":{"id":"117fb710-de75-4de7-b101-db7f63248407"},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":null,"id":"9ab20da8-f2ff-4125-98ed-5c5c0253cebc","metadata":{"id":"9ab20da8-f2ff-4125-98ed-5c5c0253cebc"},"outputs":[],"source":["# Drop rows where 'Status' has null values\n","df = df.dropna(subset=['Status'])\n","\n","# Verify if there are any remaining null values\n","print(df.isna().sum())\n"]},{"cell_type":"code","execution_count":null,"id":"a3ce488e-94db-47c7-8c72-4bb2a9874a35","metadata":{"id":"a3ce488e-94db-47c7-8c72-4bb2a9874a35"},"outputs":[],"source":["# For LAT and LON, remove rows with coordinates outside the expected range\n","# Assuming the dataset is for a specific geographic area, e.g., Los Angeles\n","df = df[(df['LAT'] > 33.5) & (df['LAT'] < 34.5) & (df['LON'] < -118) & (df['LON'] > -119)]"]},{"cell_type":"code","execution_count":null,"id":"511185b4-ab15-4b8f-a0b9-91ecbe430094","metadata":{"id":"511185b4-ab15-4b8f-a0b9-91ecbe430094"},"outputs":[],"source":["# One-hot encode AREA NAME, Vict Sex, Vict Descent, Status Desc, and Crm Cd Desc\n","df = pd.get_dummies(df, columns=['AREA NAME', 'Vict Sex', 'Vict Descent', 'Status Desc', 'Crm Cd Desc'], drop_first=True)\n"]},{"cell_type":"code","execution_count":null,"id":"e297778e-751c-4842-98b4-a6415aa80a1f","metadata":{"id":"e297778e-751c-4842-98b4-a6415aa80a1f"},"outputs":[],"source":["# Extracting hour from TIME OCC (assuming it's in a 24-hour format)\n","df['Hour'] = df['TIME OCC'] // 100\n","\n","# Convert DATE OCC to datetime format and extract year, month, and day features\n","df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], errors='coerce')\n","df['Year'] = df['DATE OCC'].dt.year\n","df['Month'] = df['DATE OCC'].dt.month\n","df['Day'] = df['DATE OCC'].dt.day\n","\n","# Drop the original date and time columns if not needed\n","df = df.drop(columns=['DATE OCC', 'TIME OCC', 'DR_NO'])\n"]},{"cell_type":"code","execution_count":null,"id":"a206d51c-d8d3-431f-8128-168264e2ed96","metadata":{"id":"a206d51c-d8d3-431f-8128-168264e2ed96"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","# Define numerical columns to scale\n","numerical_cols = ['Vict Age', 'Rpt Dist No', 'Premis Cd', 'Weapon Used Cd', 'LAT', 'LON', 'Hour']\n","\n","# Apply standard scaling\n","scaler = StandardScaler()\n","df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n"]},{"cell_type":"code","execution_count":null,"id":"8a664352-b9df-4a0e-be53-4c66a00acb0b","metadata":{"id":"8a664352-b9df-4a0e-be53-4c66a00acb0b","scrolled":true},"outputs":[],"source":["# Check final data structure\n","print(df.info())\n","print(df.describe())\n"]},{"cell_type":"markdown","id":"9104cad6-2dd4-4313-80ba-4676558b91f9","metadata":{"id":"9104cad6-2dd4-4313-80ba-4676558b91f9"},"source":["The DataFrame has 987,743 rows, 209 columns, and various data types, using 357.2 MB of memory. Key fields include area codes, district codes, age data with outliers, codes for premises, weapons, and crimes, as well as geographic and time-related data. Some columns may need encoding, and outliers may require cleaning."]},{"cell_type":"code","execution_count":null,"id":"bf011d10-2499-4fe0-a638-9e5e73c0554e","metadata":{"id":"bf011d10-2499-4fe0-a638-9e5e73c0554e"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"id":"d6108192-0e17-435e-877b-f29860b981b4","metadata":{"id":"d6108192-0e17-435e-877b-f29860b981b4"},"outputs":[],"source":["df.head(500)"]},{"cell_type":"code","execution_count":null,"id":"e0a09556-bafb-40b1-bab5-d3bf153ed4e7","metadata":{"id":"e0a09556-bafb-40b1-bab5-d3bf153ed4e7"},"outputs":[],"source":["print(df.columns)\n"]},{"cell_type":"code","execution_count":null,"id":"72b96899-269b-4089-8b3b-e4ef0af9a174","metadata":{"id":"72b96899-269b-4089-8b3b-e4ef0af9a174"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"id":"c50f7b02-e0fb-477f-b78f-0ce02f5d6d8b","metadata":{"id":"c50f7b02-e0fb-477f-b78f-0ce02f5d6d8b","scrolled":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Assuming your data is in df\n","\n","# Step 1: Check for remaining missing values\n","print(\"Missing Values Summary:\")\n","print(df.isnull().sum()[df.isnull().sum() > 0])\n","\n","# Step 2: Check if any one-hot encoded columns can be simplified\n","# Example: Remove one-hot columns for 'AREA NAME' if not needed\n","one_hot_area_cols = [col for col in df.columns if 'AREA NAME_' in col]\n","df.drop(columns=one_hot_area_cols, inplace=True)\n","\n","# Step 3: Recheck outliers in important columns\n","from scipy.stats import zscore\n","\n","# Outlier detection for 'Vict Age'\n","if 'Vict Age' in df.columns:\n","    df = df[(np.abs(zscore(df['Vict Age'])) < 3)]  # within 3 standard deviations\n","\n","# Outlier detection for 'Hour'\n","if 'Hour' in df.columns:\n","    df = df[(np.abs(zscore(df['Hour'])) < 3)]\n","\n","# Step 4: Check the final summary of the DataFrame\n","print(\"Final DataFrame Summary:\")\n","print(df.info())\n","print(df.describe())\n","\n","# Display a few rows to verify the cleaned data\n","print(df.head())\n"]},{"cell_type":"code","execution_count":null,"id":"002154f0-483a-4df7-91bf-276b8cf6d94e","metadata":{"id":"002154f0-483a-4df7-91bf-276b8cf6d94e"},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"id":"35f1282d-99b8-4fb7-965a-9891afa73e17","metadata":{"id":"35f1282d-99b8-4fb7-965a-9891afa73e17","scrolled":true},"outputs":[],"source":["# Display all column names without truncation\n","for column in df.columns:\n","    print(column)\n"]},{"cell_type":"code","execution_count":null,"id":"ab9b8bd0-03e8-4530-bb6c-be41d31b5185","metadata":{"id":"ab9b8bd0-03e8-4530-bb6c-be41d31b5185","scrolled":true},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":null,"id":"fb0edc98-9a18-45b1-8534-e61d1a07762b","metadata":{"id":"fb0edc98-9a18-45b1-8534-e61d1a07762b"},"outputs":[],"source":["# Identify the one-hot encoded columns related to crime description\n","crime_columns = [col for col in df.columns if col.startswith(\"Crm Cd Desc_\")]\n","\n","# Create a new target column by finding the column with the value '1' in each row\n","df['Crime_Type'] = df[crime_columns].idxmax(axis=1)\n","\n","# Remove the \"Crm Cd Desc_*\" one-hot encoded columns\n","df.drop(columns=crime_columns, inplace=True)\n","\n","# Now 'Crime_Type' is your target column, which contains the crime type for each row\n"]},{"cell_type":"code","execution_count":null,"id":"7ee4f218-8d2d-4bae-90ae-b50bc2e71d83","metadata":{"id":"7ee4f218-8d2d-4bae-90ae-b50bc2e71d83"},"outputs":[],"source":["df.columns.tolist()"]},{"cell_type":"code","execution_count":null,"id":"4fce706d-a60a-4811-8328-a720c4442eaa","metadata":{"id":"4fce706d-a60a-4811-8328-a720c4442eaa"},"outputs":[],"source":["\n","# Group by Year and Crime_Type to see trends over time\n","crime_trends_yearly = df.groupby(['Year', 'Crime_Type']).size().unstack(fill_value=0)\n"]},{"cell_type":"markdown","id":"6d4cba30-cc70-4f55-b083-6332d90d4a93","metadata":{"id":"6d4cba30-cc70-4f55-b083-6332d90d4a93"},"source":["Question 1. What are the most common types of crimes reported over time?"]},{"cell_type":"code","execution_count":null,"id":"3327d5f2-6417-4400-8897-60f9efe077ab","metadata":{"id":"3327d5f2-6417-4400-8897-60f9efe077ab"},"outputs":[],"source":["#visualize the frequency of each crime type over the years."]},{"cell_type":"code","execution_count":null,"id":"bf2fb5bd-dfd3-47d2-83f1-e8c576c7c6bc","metadata":{"id":"bf2fb5bd-dfd3-47d2-83f1-e8c576c7c6bc"},"outputs":[],"source":["# Get the top 10 most common crime types\n","top_crimes = df['Crime_Type'].value_counts().head(10).index\n","filtered_data = crime_trends_yearly[top_crimes]\n","\n","# Plot trends for the top crimes only\n","plt.figure(figsize=(14, 8))\n","for crime_type in filtered_data.columns:\n","    plt.plot(filtered_data.index, filtered_data[crime_type], label=crime_type)\n","\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Number of Incidents\")\n","plt.title(\"Trends Over Time for Most Common Crime Types\")\n","plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n","plt.xticks(rotation=45)\n","plt.show()\n"]},{"cell_type":"markdown","id":"ed52efd2-4ecb-468e-bd45-b9a0640a93eb","metadata":{"id":"ed52efd2-4ecb-468e-bd45-b9a0640a93eb"},"source":["The line plot illustrates trends in the ten most common crime types over recent years. \"Vehicle - Stolen\" consistently ranks as the most frequent crime, while other types like \"Theft Plain - Petty\" and \"Battery - Simple Assault\" show moderate frequency. Notably, \"Theft of Identity\" had a significant spike around 2021 but declined thereafter. Overall, the graph reveals varying patterns for different crimes, with some showing steady trends and others displaying fluctuations over time."]},{"cell_type":"code","execution_count":null,"id":"e3863919-aeda-48ea-8e2f-1072fc4211ff","metadata":{"id":"e3863919-aeda-48ea-8e2f-1072fc4211ff"},"outputs":[],"source":["#Heatmap Corelation"]},{"cell_type":"code","execution_count":null,"id":"12dd702b-e7dc-4140-90cb-30dc7fe1b827","metadata":{"id":"12dd702b-e7dc-4140-90cb-30dc7fe1b827"},"outputs":[],"source":["import seaborn as sns\n","\n","plt.figure(figsize=(14, 10))\n","sns.heatmap(crime_trends_yearly[top_crimes].T, cmap=\"YlGnBu\", annot=False, cbar=True)\n","plt.title(\"Heatmap of Most Common Crime Types Over Time\")\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Crime Type\")\n","plt.show()\n"]},{"cell_type":"markdown","id":"e763d8ba-1fc4-423f-92f7-200f101fb156","metadata":{"id":"e763d8ba-1fc4-423f-92f7-200f101fb156"},"source":["#The heatmap provides a visual representation of the frequency of common crime types over time. Darker shades indicate higher incidences, while lighter shades show lower ones. \"Vehicle - Stolen\" consistently appears as a highly frequent crime across the years. Notably, \"Theft of Identity\" had a peak around 2021, shown by the darker blue. This heatmap effectively highlights fluctuations in crime occurrences, helping to identify trends for each crime type over different years."]},{"cell_type":"markdown","id":"599cdaca-19df-412d-bbbd-79b54a027e55","metadata":{"id":"599cdaca-19df-412d-bbbd-79b54a027e55"},"source":["1.\tWhat are the most common types of crimes reported over time?\n","   Answer: Vehicle - Stolen: Consistently reported at high levels each year. Battery - Simple Assault: Another frequently reported crime type. Burglary      from Vehicle: Maintains a steady frequency over the years.Theft of Identity: Shows a significant spike around 2021.Vandalism - Felony ($400 & Over,        All Church Vandalisms): Regularly reported, though with some fluctuations.\n","These crime types remain prevalent throughout the years, with \"Vehicle - Stolen\" being particularly common."]},{"cell_type":"markdown","id":"d50c1d00-b2be-408b-a757-057cd4b22240","metadata":{"id":"d50c1d00-b2be-408b-a757-057cd4b22240"},"source":["Question 2: Which areas have the highest crime rates, and how do they change over time?"]},{"cell_type":"code","execution_count":null,"id":"7cda1515-3252-41f6-9228-7413e55d7cbf","metadata":{"id":"7cda1515-3252-41f6-9228-7413e55d7cbf"},"outputs":[],"source":["# Group by AREA and Year to see the frequency of crimes in each area annually\n","area_trends_yearly = df.groupby(['Year', 'AREA']).size().unstack(fill_value=0)\n"]},{"cell_type":"code","execution_count":null,"id":"fb5f6017-be27-4fb7-8e6d-752af96786eb","metadata":{"id":"fb5f6017-be27-4fb7-8e6d-752af96786eb"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(14, 10))\n","sns.heatmap(area_trends_yearly, cmap=\"YlOrRd\", annot=False, cbar=True)\n","plt.title(\"Heatmap of Crime Frequency by Area Over Time\")\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Area\")\n","plt.show()\n"]},{"cell_type":"markdown","id":"b92ef7b3-150c-4afe-a8d5-a4b311f2149a","metadata":{"id":"b92ef7b3-150c-4afe-a8d5-a4b311f2149a"},"source":["The heatmap displays crime frequency across different areas over several years. Darker shades indicate higher crime rates, with areas 1, 12, and 13 consistently showing higher frequencies over time. These areas experienced particularly elevated crime rates around 2022 and 2023, while other areas generally show lighter shades, indicating lower crime occurrences."]},{"cell_type":"code","execution_count":null,"id":"1d52c1c4-0831-4cb9-9cb0-c1133b146394","metadata":{"id":"1d52c1c4-0831-4cb9-9cb0-c1133b146394"},"outputs":[],"source":["# Transpose the data for easier plotting with an area chart\n","area_trends_yearly_transposed = area_trends_yearly.T\n","\n","plt.figure(figsize=(14, 8))\n","area_trends_yearly_transposed.plot(kind='area', stacked=True, figsize=(14, 8), colormap='tab20')\n","plt.title(\"Crime Frequency in Different Areas Over Time\")\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Number of Crimes\")\n","plt.legend(title=\"Area\", loc='upper left', bbox_to_anchor=(1.0, 1.0))\n","plt.show()\n"]},{"cell_type":"markdown","id":"78022cc4-c875-4b13-8d2c-7bde2dc37573","metadata":{"id":"78022cc4-c875-4b13-8d2c-7bde2dc37573"},"source":["The area chart shows crime frequency across areas over time. Each color represents an area, with peaks indicating higher crime rates. Some areas consistently have more crimes, contributing significantly to total crime rates, while others fluctuate. Peaks and dips highlight changes in crime trends over the years."]},{"cell_type":"markdown","id":"3a448866-42cc-4c0f-96d1-ad8903f955d6","metadata":{"id":"3a448866-42cc-4c0f-96d1-ad8903f955d6"},"source":["Question 2: Which areas have the highest crime rates, and how do they change over time?\n","Answer: The areas with the highest crime rates, as shown in both the heatmap and area chart, include Area 1, Area 12, and Area 13. These areas consistently report higher crime frequencies over the years. Crime rates in these areas show fluctuations rather than a consistent increase, with some years experiencing peaks and others showing declines."]},{"cell_type":"markdown","id":"11a780ff-4861-48c5-9f3a-8d8757894ddb","metadata":{"id":"11a780ff-4861-48c5-9f3a-8d8757894ddb"},"source":["Question 3: Is there a correlation between time of day (hour) and specific types of crimes?"]},{"cell_type":"code","execution_count":null,"id":"92eda034-def9-47f2-a648-718812f18fd6","metadata":{"id":"92eda034-def9-47f2-a648-718812f18fd6"},"outputs":[],"source":["# Group by Hour and Crime_Type to find the frequency of each crime type at each hour\n","crime_by_hour = df.groupby(['Hour', 'Crime_Type']).size().unstack(fill_value=0)\n"]},{"cell_type":"code","execution_count":null,"id":"d26125ae-1d21-4840-9759-e6728d205433","metadata":{"id":"d26125ae-1d21-4840-9759-e6728d205433"},"outputs":[],"source":["# Select the top 10 most frequent crime types\n","top_crime_types = df['Crime_Type'].value_counts().head(10).index\n","crime_by_hour_top = crime_by_hour[top_crime_types]\n","\n","plt.figure(figsize=(14, 8))\n","sns.heatmap(crime_by_hour_top, cmap=\"coolwarm\", cbar=True)\n","plt.title(\"Frequency of Top Crime Types by Hour of the Day\")\n","plt.xlabel(\"Crime Type\")\n","plt.ylabel(\"Hour\")\n","plt.show()\n"]},{"cell_type":"markdown","id":"bd17c1af-5959-4f1d-83f2-c5ae903fdc91","metadata":{"id":"bd17c1af-5959-4f1d-83f2-c5ae903fdc91"},"source":["The heatmap shows the distribution of the top 10 most frequent crime types by hour of the day. \"Vehicle - Stolen\" has the highest frequency across all hours, represented by the darkest shade on the left. Other crimes like \"Battery - Simple Assault\" and \"Burglary from Vehicle\" show moderate frequencies, with lighter shades indicating lower occurrences. This visualization highlights that certain crimes are more prevalent than others but does not indicate strong variation by hour for these top crime types."]},{"cell_type":"markdown","id":"1d61c0a4-4e65-49e8-a5a8-34e47bbbd435","metadata":{"id":"1d61c0a4-4e65-49e8-a5a8-34e47bbbd435"},"source":["Question 3: Is there a correlation between time of day (hour) and specific types of crimes?\n","Answer: There’s no strong correlation between specific hours and top crime types. Crimes like \"Vehicle - Stolen\" occur consistently across all hours, with no significant hourly fluctuations among the top types."]},{"cell_type":"code","execution_count":null,"id":"66cbd644-12ab-4611-99a3-7a90dec9b3da","metadata":{"id":"66cbd644-12ab-4611-99a3-7a90dec9b3da"},"outputs":[],"source":["Question 4: How does crime distribution vary by demographic factors (like victim’s sex or age)?"]},{"cell_type":"code","execution_count":null,"id":"f0de51a4-4a42-40bc-af91-5da7c577d266","metadata":{"id":"f0de51a4-4a42-40bc-af91-5da7c577d266"},"outputs":[],"source":["# Select the one-hot encoded columns for victim sex\n","victim_sex_columns = ['Vict Sex_F', 'Vict Sex_M', 'Vict Sex_H', 'Vict Sex_Unknown', 'Vict Sex_X']\n","\n","# Group by Crime_Type and sum across victim sex columns\n","crime_by_sex = df.groupby('Crime_Type')[victim_sex_columns].sum()\n"]},{"cell_type":"code","execution_count":null,"id":"da694f0d-28c9-4ed3-a5ef-9508d22d1019","metadata":{"id":"da694f0d-28c9-4ed3-a5ef-9508d22d1019"},"outputs":[],"source":["# Select one-hot encoded columns for victim sex\n","victim_sex_columns = ['Vict Sex_F', 'Vict Sex_M', 'Vict Sex_H', 'Vict Sex_Unknown', 'Vict Sex_X']\n","\n","# Group by Crime_Type and sum the counts for each sex\n","crime_by_sex = df.groupby('Crime_Type')[victim_sex_columns].sum()\n","\n","# Focus on the top 10 crime types for readability\n","top_crimes = df['Crime_Type'].value_counts().head(10).index\n","filtered_crime_by_sex = crime_by_sex.loc[top_crimes]\n","\n","# Plotting the distribution by sex\n","filtered_crime_by_sex.plot(kind='bar', stacked=True, figsize=(14, 8), width=0.8)\n","plt.title(\"Crime Distribution by Victim's Sex (Top 10 Crimes)\")\n","plt.xlabel(\"Crime Type\")\n","plt.ylabel(\"Number of Incidents\")\n","plt.legend(title=\"Victim's Sex\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","id":"e67284d6-bed7-4bf2-85a2-2615ff7664c0","metadata":{"id":"e67284d6-bed7-4bf2-85a2-2615ff7664c0"},"source":["The chart shows \"Vehicle - Stolen\" as the most common crime, affecting both male and female victims significantly. Other frequent crimes like \"Battery - Simple Assault\" and \"Burglary from Vehicle\" also impact both sexes, but at lower rates."]},{"cell_type":"markdown","id":"27239b82-4ddc-4161-bbd8-cf2d8207c0ea","metadata":{"id":"27239b82-4ddc-4161-bbd8-cf2d8207c0ea"},"source":["Question 4: How does crime distribution vary by demographic factors (like victim’s sex or age)?\n","Answer: \"Vehicle - Stolen\" is the most frequent crime, impacting both sexes. Crimes like \"Battery - Simple Assault\" and \"Burglary from Vehicle\" also affect both genders. The 19-35 age group reports the most incidents, with crime rates generally lower in older age groups."]},{"cell_type":"markdown","id":"68b10598-7bbe-4d7b-9639-676338faf34c","metadata":{"id":"68b10598-7bbe-4d7b-9639-676338faf34c"},"source":["Question 5: Are certain types of crimes more frequent on specific days (e.g., weekends vs. weekdays)?"]},{"cell_type":"code","execution_count":null,"id":"fcbaceb5-ae04-4ee4-832e-879b4bdb3cca","metadata":{"id":"fcbaceb5-ae04-4ee4-832e-879b4bdb3cca"},"outputs":[],"source":["# Convert the Date Rptd column to day of the week (if not already in dataset)\n","df['DayOfWeek'] = pd.to_datetime(df['Date Rptd']).dt.day_name()\n","\n","# Group by Crime_Type and DayOfWeek\n","crime_by_day = df.groupby(['Crime_Type', 'DayOfWeek']).size().unstack(fill_value=0)\n","\n","# Focus on top 10 crimes for readability\n","top_crimes = df['Crime_Type'].value_counts().head(10).index\n","filtered_crime_by_day = crime_by_day.loc[top_crimes]\n","\n","# Plot the data\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(14, 8))\n","sns.heatmap(filtered_crime_by_day, cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n","plt.title(\"Crime Frequency by Day of the Week for Top 10 Crimes\")\n","plt.xlabel(\"Day of the Week\")\n","plt.ylabel(\"Crime Type\")\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","id":"bc52bd22-d1a7-48fc-bdee-09617d19f186","metadata":{"id":"bc52bd22-d1a7-48fc-bdee-09617d19f186"},"source":["The heatmap shows that \"Vehicle - Stolen\" and \"Battery - Simple Assault\" are more frequent on weekdays, especially Fridays, than weekends. In contrast, crimes like \"Theft Plain - Petty ($950 & Under)\" and \"Intimate Partner - Simple Assault\" are steady across the week with minor fluctuations. This suggests certain crimes peak on weekdays, likely tied to daily activity patterns."]},{"cell_type":"markdown","id":"7517274f-fce6-4273-81d2-78b1e024bc78","metadata":{"id":"7517274f-fce6-4273-81d2-78b1e024bc78"},"source":["Question 5: Are certain types of crimes more frequent on specific days (e.g., weekends vs. weekdays)?\n","Answer: Yes, certain crimes are more frequent on specific days. For example, \"Vehicle - Stolen\" and \"Battery - Simple Assault\" are more common on weekdays, particularly on Fridays, than on weekends. Other crimes, like \"Theft Plain - Petty ($950 & Under)\" and \"Intimate Partner - Simple Assault,\" remain relatively steady throughout the week. This suggests that some crimes peak on weekdays, likely influenced by daily routines and activity patterns."]},{"cell_type":"code","execution_count":null,"id":"08b6f060-1fcb-449f-916e-02021f6ed04b","metadata":{"id":"08b6f060-1fcb-449f-916e-02021f6ed04b"},"outputs":[],"source":["Questiom 6: Is there a seasonal trend in crime occurrence (monthly or yearly)?"]},{"cell_type":"code","execution_count":null,"id":"ca098268-4516-4282-999b-c52010a0b303","metadata":{"id":"ca098268-4516-4282-999b-c52010a0b303"},"outputs":[],"source":["# Ensure 'Date Rptd' is in datetime format\n","df['Date Rptd'] = pd.to_datetime(df['Date Rptd'], errors='coerce')  # Convert to datetime, handling errors\n","\n","# Now you can use the .dt accessor\n","df['Year-Month'] = df['Date Rptd'].dt.to_period('M')\n","\n","# Group by the new 'Year-Month' column to get monthly totals\n","monthly_crime_trends = df.groupby('Year-Month').size()\n","\n","# Convert index to datetime for plotting\n","monthly_crime_trends.index = monthly_crime_trends.index.to_timestamp()\n","\n","# Plot monthly crime trends over time\n","plt.figure(figsize=(14, 8))\n","plt.plot(monthly_crime_trends.index, monthly_crime_trends)\n","plt.title(\"Monthly Crime Trends Over Time\")\n","plt.xlabel(\"Year-Month\")\n","plt.ylabel(\"Number of Incidents\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","id":"53267aac-0dd6-4060-8123-e69110c11cd7","metadata":{"id":"53267aac-0dd6-4060-8123-e69110c11cd7"},"source":["The line plot illustrates monthly crime trends over time, showing a generally stable level of incidents from 2020 through early 2023, with monthly incidents hovering around 15,000 to 20,000. However, there’s a noticeable decline in crime frequency starting in 2023, dropping sharply toward 2024."]},{"cell_type":"markdown","id":"c0a848f4-b1e0-4bd7-ae20-3e31468cdb1b","metadata":{"id":"c0a848f4-b1e0-4bd7-ae20-3e31468cdb1b"},"source":["Questiom 6: Is there a seasonal trend in crime occurrence (monthly or yearly)?\n","Answer: Yes, there appears to be a seasonal trend in crime occurrence. From 2020 to early 2023, crime incidents remain relatively stable, with minor fluctuations each month. However, a sharp decline in reported incidents begins in 2023 and continues into 2024. This pattern suggests either a seasonal reduction in crime or potential external factors, such as policy changes or enforcement measures, that led to fewer reported incidents in the later period."]},{"cell_type":"code","execution_count":null,"id":"8e5c6668-a9c9-45b8-84ff-634e31dcc756","metadata":{"id":"8e5c6668-a9c9-45b8-84ff-634e31dcc756"},"outputs":[],"source":["Question 7:\tWhich features (e.g., location, time, type of weapon) are most predictive of specific crime types?"]},{"cell_type":"code","execution_count":null,"id":"937775af-ca4b-4659-a771-e2170ae87a29","metadata":{"id":"937775af-ca4b-4659-a771-e2170ae87a29"},"outputs":[],"source":["# Assuming your main dataframe is named `df`\n","# Step 1: Select relevant columns including 'Crime_Type' as the target variable\n","selected_columns = ['AREA', 'Hour', 'Premis Desc', 'Weapon Desc', 'Crime_Type']  # Adjust this list as needed\n","df_selected = df[selected_columns].copy()\n","\n","# Step 2: Perform one-hot encoding on categorical columns if needed\n","df_selected = pd.get_dummies(df_selected, columns=['Premis Desc', 'Weapon Desc'], drop_first=True)\n","\n","# Step 3: Sample the dataset to reduce memory load\n","df_sampled = df_selected.sample(frac=0.3, random_state=42)  # Use 30% of data\n","\n","# Step 4: Define X and y\n","X = df_sampled.drop(columns=['Crime_Type'])\n","y = df_sampled['Crime_Type']\n"]},{"cell_type":"markdown","id":"oa-ML19L_le3","metadata":{"id":"oa-ML19L_le3"},"source":["To identify which features (e.g., location, time, type of weapon) are most predictive of specific crime types, I selected key columns (AREA, Hour, Premis Desc, Weapon Desc, Crime_Type) for analysis. Categorical variables like Premis Desc and Weapon Desc were one-hot encoded to convert them into numerical format, and 30% of the data was sampled to reduce memory load while maintaining representative data. Finally, the dataset was split into X (features) and y (target variable, Crime_Type) for further predictive modeling."]},{"cell_type":"code","execution_count":null,"id":"4dd5ae05-e373-4860-80ec-35bb07e417c7","metadata":{"id":"4dd5ae05-e373-4860-80ec-35bb07e417c7"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"id":"a0ff0c3a-880a-474b-ac5f-285b99c3223a","metadata":{"id":"a0ff0c3a-880a-474b-ac5f-285b99c3223a"},"outputs":[],"source":["# Use an even smaller sample, for example, 10% of the data\n","df_sampled = df_selected.sample(frac=0.1, random_state=42)  # Use 10% of data\n","X = df_sampled.drop(columns=['Crime_Type'])\n","y = df_sampled['Crime_Type']\n"]},{"cell_type":"code","execution_count":null,"id":"e2a71a4a-6289-451d-a726-cc752747c391","metadata":{"id":"e2a71a4a-6289-451d-a726-cc752747c391"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n"]},{"cell_type":"code","execution_count":null,"id":"d4272956-afbb-4544-9abf-b541003508ba","metadata":{"id":"d4272956-afbb-4544-9abf-b541003508ba"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Use a smaller sample of the data\n","df_sampled = df_selected.sample(frac=0.1, random_state=42)  # Use 10% of data\n","X = df_sampled.drop(columns=['Crime_Type'])\n","y = df_sampled['Crime_Type']\n","\n","# Initialize and train the Random Forest model\n","model = RandomForestClassifier(n_estimators=50, random_state=42)  # Reduce number of trees\n","model.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"2d6acec7-dfd6-48cf-81fd-0226e419eb3f","metadata":{"id":"2d6acec7-dfd6-48cf-81fd-0226e419eb3f"},"outputs":[],"source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","# Predict on the test set\n","y_pred_rf = model.predict(X_test)  # For Random Forest\n","y_pred_lr = model.predict(X_test)  # For Logistic Regression\n","\n","# Random Forest Performance\n","print(\"Random Forest Classification Report:\")\n","print(classification_report(y_test, y_pred_rf))\n","print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n","\n","# Logistic Regression Performance\n","print(\"Logistic Regression Classification Report:\")\n","print(classification_report(y_test, y_pred_lr))\n","print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n"]},{"cell_type":"markdown","id":"NVKI9LSy_8TX","metadata":{"id":"NVKI9LSy_8TX"},"source":["In this step, a Random Forest Classifier was implemented to predict crime types. Despite using balanced class weights and an oversampled dataset, the model's performance varied significantly across classes, with lower precision and recall for less frequent crime categories. This indicates that class imbalance in the dataset, even after oversampling, likely influenced the model's ability to generalize for underrepresented classes. Additionally, the large number of classes and overlapping features may have contributed to reduced accuracy for certain crime types. Further optimization, such as advanced feature selection or alternative resampling techniques, could improve performance."]},{"cell_type":"markdown","id":"bad65109-d1af-4ca2-b6c3-db88695be990","metadata":{"id":"bad65109-d1af-4ca2-b6c3-db88695be990"},"source":["Both models have low overall performance, suggesting that predicting crime types based on the selected features is challenging."]},{"cell_type":"code","execution_count":null,"id":"3fd0f6f6-6239-429e-b48c-7442619c6e88","metadata":{"id":"3fd0f6f6-6239-429e-b48c-7442619c6e88"},"outputs":[],"source":["# Simplify the 'Crime_Type' categories by mapping them to broader classes\n","crime_type_mapping = {\n","    'Crm Cd Desc_VEHICLE - STOLEN': 'Theft',\n","    'Crm Cd Desc_BATTERY - SIMPLE ASSAULT': 'Assault',\n","    # Add more mappings based on observed crime types, grouping similar ones\n","}\n","\n","df['Crime_Type'] = df['Crime_Type'].replace(crime_type_mapping)\n"]},{"cell_type":"code","execution_count":null,"id":"c472d50c-b9b4-41cd-a8d7-123e794ae0f7","metadata":{"id":"c472d50c-b9b4-41cd-a8d7-123e794ae0f7","scrolled":true},"outputs":[],"source":["# Display the counts of each crime type to verify distribution\n","print(df['Crime_Type'].value_counts())\n"]},{"cell_type":"markdown","id":"Y9pwrDWtAeDN","metadata":{"id":"Y9pwrDWtAeDN"},"source":["Crime_Type variable was re-mapped into broader categories to address the high granularity of the original labels, which contributed to data sparsity and poor model performance. By grouping similar or rare crime types into fewer broader categories (e.g., Theft, Assault), the dataset became more balanced and easier to model."]},{"cell_type":"code","execution_count":null,"id":"f988ecfc-a85e-4ed1-8aca-58c4b7931342","metadata":{"id":"f988ecfc-a85e-4ed1-8aca-58c4b7931342","scrolled":true},"outputs":[],"source":["# Define a threshold for rare crimes (e.g., crimes with less than 100 occurrences)\n","rare_crime_threshold = 100\n","\n","# Identify rare crimes\n","rare_crimes = df['Crime_Type'].value_counts()[df['Crime_Type'].value_counts() < rare_crime_threshold].index\n","\n","# Replace rare crimes with 'Other'\n","\n","df['Crime_Type'] = df['Crime_Type'].apply(lambda x: 'Other' if x in rare_crimes else x)\n","\n","# Check the new distribution of 'Crime_Type' after grouping\n","print(df['Crime_Type'].value_counts())\n"]},{"cell_type":"markdown","id":"sDaVbwrdBWXP","metadata":{"id":"sDaVbwrdBWXP"},"source":["rare classes with a frequency below a defined threshold were grouped into a new Other category. This step further reduced the imbalance by ensuring that rare categories did not disproportionately affect the model's ability to generalize. These changes aimed to improve the classifier's performance by providing more representative and balanced training data, enabling better predictions for the redefined Crime_Type variable."]},{"cell_type":"code","execution_count":null,"id":"6ca05b24-0c6a-414c-9cd8-fe30ea61d236","metadata":{"id":"6ca05b24-0c6a-414c-9cd8-fe30ea61d236"},"outputs":[],"source":["# Assuming 'Hour' and 'Day' columns exist in your data\n","def get_time_of_day(hour):\n","    if 5 <= hour < 12:\n","        return 'Morning'\n","    elif 12 <= hour < 17:\n","        return 'Afternoon'\n","    elif 17 <= hour < 21:\n","        return 'Evening'\n","    else:\n","        return 'Night'\n","\n","df['Time_of_Day'] = df['Hour'].apply(get_time_of_day)\n","df['Is_Weekend'] = df['Day'].apply(lambda x: 1 if x in ['Saturday', 'Sunday'] else 0)\n"]},{"cell_type":"markdown","id":"9nIDwkTsBvH5","metadata":{"id":"9nIDwkTsBvH5"},"source":["New features were created to enhance prediction: Time_of_Day categorized Hour into periods like Morning and Night, capturing temporal patterns, while Is_Weekend flagged weekends (1) vs. weekdays (0) to identify weekend crime trends. These additions improve the model's ability to capture temporal and contextual influences."]},{"cell_type":"code","execution_count":null,"id":"e2a5a57a-9ced-4a3b-9e9f-0b7ba7b8267b","metadata":{"id":"e2a5a57a-9ced-4a3b-9e9f-0b7ba7b8267b"},"outputs":[],"source":["df = pd.get_dummies(df, columns=['Time_of_Day', 'Premis Desc', 'Weapon Desc'], drop_first=True)\n"]},{"cell_type":"code","execution_count":null,"id":"c4edeeb8-fd4b-42ab-ade6-24f196eef8c0","metadata":{"id":"c4edeeb8-fd4b-42ab-ade6-24f196eef8c0"},"outputs":[],"source":["df_sampled = df.sample(frac=0.1, random_state=42)  # Reduce to 10% of the data\n","X = df_sampled.drop(columns=['Crime_Type'])\n","y = df_sampled['Crime_Type']\n"]},{"cell_type":"code","execution_count":null,"id":"571d4ce4-72a8-4494-ae2a-6d735699dd85","metadata":{"id":"571d4ce4-72a8-4494-ae2a-6d735699dd85"},"outputs":[],"source":["X_numeric = X.select_dtypes(include=['int64', 'float64'])  # Select only numeric columns"]},{"cell_type":"code","execution_count":null,"id":"195c1102-4a0e-4870-a37e-b9bb7ef9a3d7","metadata":{"id":"195c1102-4a0e-4870-a37e-b9bb7ef9a3d7"},"outputs":[],"source":["from sklearn.feature_selection import VarianceThreshold\n","\n","selector = VarianceThreshold(threshold=0.01)  # Adjust threshold as needed\n","X_reduced = selector.fit_transform(X_numeric)\n"]},{"cell_type":"code","execution_count":null,"id":"19f6b641-0f6a-4e3f-8a51-3964200151ad","metadata":{"id":"19f6b641-0f6a-4e3f-8a51-3964200151ad"},"outputs":[],"source":["kept_columns = X_numeric.columns[selector.get_support()]\n","X_reduced = pd.DataFrame(X_reduced, columns=kept_columns)\n"]},{"cell_type":"code","execution_count":null,"id":"3e04f670-6867-4e3e-85c2-9d78a61a1661","metadata":{"id":"3e04f670-6867-4e3e-85c2-9d78a61a1661"},"outputs":[],"source":["print(\"Reduced dataset shape:\", X_reduced.shape)\n","print(X_reduced.head())"]},{"cell_type":"code","execution_count":null,"id":"DiSbIRGGAGNX","metadata":{"id":"DiSbIRGGAGNX"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from imblearn.over_sampling import SMOTE\n","\n","# Filter numeric columns\n","X_reduced = X_reduced.select_dtypes(include=[np.number])\n","\n","# Reset indices to ensure alignment\n","X_reduced = X_reduced.reset_index(drop=True)\n","y = y.reset_index(drop=True)\n","\n","# Apply SMOTE for balancing\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X_reduced, y)\n","\n","# Check shapes\n","print(f\"X_resampled shape: {X_resampled.shape}\")\n","print(f\"y_resampled shape: {y_resampled.shape}\")\n"]},{"cell_type":"markdown","id":"oC9seBwfB-qk","metadata":{"id":"oC9seBwfB-qk"},"source":["The dataset was reduced to 10 key features to focus on the most relevant variables for prediction. This dimensionality reduction simplifies the model, improves computational efficiency, and reduces noise, enabling more accurate and faster predictions. The reduced dataset retains essential features like AREA, Hour, LAT, and LON while ensuring critical information is preserved."]},{"cell_type":"code","execution_count":null,"id":"HWkloMGnAGZE","metadata":{"id":"HWkloMGnAGZE"},"outputs":[],"source":["X = X.reset_index(drop=True)\n","y = y.reset_index(drop=True)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ae4a0a94-77a7-47c8-8753-9debc923fdf7","metadata":{"id":"ae4a0a94-77a7-47c8-8753-9debc923fdf7"},"outputs":[],"source":["from imblearn.over_sampling import SMOTE\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X_reduced, y)\n"]},{"cell_type":"markdown","id":"Dai0QDRnCMfU","metadata":{"id":"Dai0QDRnCMfU"},"source":["SMOTE (Synthetic Minority Oversampling Technique) was applied to address class imbalance in the dataset. It generates synthetic samples for underrepresented classes, ensuring a balanced distribution of target labels. This step enhances the model's ability to learn patterns from all classes effectively, improving prediction performance for minority classes."]},{"cell_type":"code","execution_count":null,"id":"c6dfd796-c0ad-450b-9a2c-29d978d4026c","metadata":{"id":"c6dfd796-c0ad-450b-9a2c-29d978d4026c"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"id":"962f8d9f-bd52-4ce6-b230-fe4b6f28cfc6","metadata":{"id":"962f8d9f-bd52-4ce6-b230-fe4b6f28cfc6"},"outputs":[],"source":["rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n","rf_model.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"6b28c218-c624-4be7-b560-e7ba364cb918","metadata":{"id":"6b28c218-c624-4be7-b560-e7ba364cb918"},"outputs":[],"source":[" # Make predictions on the test set\n","y_pred = rf_model.predict(X_test)\n"]},{"cell_type":"markdown","id":"A1nesZx6CcQO","metadata":{"id":"A1nesZx6CcQO"},"source":["Predictions were generated on the test set using the trained Random Forest model. This step evaluates the model's performance by comparing the predicted labels (y_pred) against the actual labels in the test data, enabling the calculation of evaluation metrics like accuracy, precision, and recall."]},{"cell_type":"code","execution_count":null,"id":"93fdf25c-10c1-4c0b-8d7b-fe257ebda3a0","metadata":{"id":"93fdf25c-10c1-4c0b-8d7b-fe257ebda3a0"},"outputs":[],"source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","# Print evaluation metrics\n","print(\"Random Forest Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"]},{"cell_type":"markdown","id":"KS9b6hKHCts-","metadata":{"id":"KS9b6hKHCts-"},"source":["The classification report evaluates the Random Forest model's performance across different crime categories. It provides precision, recall, and F1-score metrics for each class. The model achieved high performance across all metrics, indicating effective prediction of crime types. The balanced class distribution (achieved via SMOTE) and feature engineering likely contributed to this strong result. The overall accuracy confirms the model's reliability in classifying the broader crime categories."]},{"cell_type":"markdown","id":"5aad57e6-7d90-4c6e-bdee-ab4ac393ded0","metadata":{"id":"5aad57e6-7d90-4c6e-bdee-ab4ac393ded0"},"source":["The Random Forest model achieved a perfect classification performance with an accuracy of 1.0 and precision, recall, and F1-scores of 1.0 for all crime types. This indicates that the model successfully predicted every crime type in the test set, suggesting excellent feature selection and balancing."]},{"cell_type":"code","execution_count":null,"id":"dc98835e-ec1c-4e71-88d1-ce987df099cb","metadata":{"id":"dc98835e-ec1c-4e71-88d1-ce987df099cb"},"outputs":[],"source":["# Get feature importance\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","feature_importance = rf_model.feature_importances_\n","features = X_train.columns\n","\n","# Plot feature importance\n","plt.figure(figsize=(10, 6))\n","plt.barh(features, feature_importance)\n","plt.xlabel(\"Feature Importance\")\n","plt.ylabel(\"Features\")\n","plt.title(\"Feature Importance for Crime Type Prediction\")\n","plt.show()\n"]},{"cell_type":"markdown","id":"4d65e856-fc7d-4f80-9295-647097c05d85","metadata":{"id":"4d65e856-fc7d-4f80-9295-647097c05d85"},"source":["The feature importance plot shows that Crm Cd is the most significant predictor of crime type, contributing over 50% of the importance. Other features like Vict Age, Premis Cd, and Weapon Used Cd also play notable roles, while location-related features (LAT, LON) and time (Hour) have lesser influence."]},{"cell_type":"code","execution_count":null,"id":"688b7924-65b9-44a4-be58-19db03141c30","metadata":{"id":"688b7924-65b9-44a4-be58-19db03141c30"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","# Select the top 20 most frequent crime types\n","top_classes = y_test.value_counts().head(20).index  # Adjust the number based on clarity\n","y_test_filtered = y_test[y_test.isin(top_classes)]\n","y_pred_filtered = y_pred[y_test.isin(top_classes)]\n","\n","# Compute confusion matrix for the filtered classes\n","cm_filtered = confusion_matrix(y_test_filtered, y_pred_filtered, labels=top_classes)\n","disp_filtered = ConfusionMatrixDisplay(confusion_matrix=cm_filtered, display_labels=top_classes)\n","\n","# Plot with enhanced clarity\n","fig, ax = plt.subplots(figsize=(12, 12))  # Adjust figure size\n","disp_filtered.plot(cmap='viridis', xticks_rotation=45, ax=ax)\n","plt.title(\"Confusion Matrix for Top 20 Crime Types\")\n","plt.xticks(fontsize=10)  # Adjust font size for x-ticks\n","plt.yticks(fontsize=10)  # Adjust font size for y-ticks\n","plt.show()\n"]},{"cell_type":"markdown","id":"5bd0c173-1b4b-4ce5-8557-409198c98999","metadata":{"id":"5bd0c173-1b4b-4ce5-8557-409198c98999"},"source":["The confusion matrix shows the model performs well for the top 20 crime types, with most predictions correct along the diagonal. Misclassifications are minimal, highlighting good accuracy for these crimes."]},{"cell_type":"markdown","id":"31cb5588-eccc-4c06-9405-36af7ce32b49","metadata":{"id":"31cb5588-eccc-4c06-9405-36af7ce32b49"},"source":["# Deep learning Model"]},{"cell_type":"code","execution_count":null,"id":"e1f029cf-e4a0-4db4-9085-42ef010d862d","metadata":{"id":"e1f029cf-e4a0-4db4-9085-42ef010d862d"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","\n","# Initialize label encoder\n","label_encoder = LabelEncoder()\n","\n","# Fit and transform the target labels\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","# Convert to one-hot encoded format\n","y_train_one_hot = to_categorical(y_train_encoded)\n","y_test_one_hot = to_categorical(y_test_encoded)\n","\n","# Check the shapes\n","print(f\"y_train shape after encoding: {y_train_one_hot.shape}\")\n","print(f\"y_test shape after encoding: {y_test_one_hot.shape}\")\n"]},{"cell_type":"markdown","id":"Q2TscpZVKJvr","metadata":{"id":"Q2TscpZVKJvr"},"source":["Target labels were encoded using LabelEncoder to convert them into numerical format, followed by one-hot encoding for compatibility with the deep learning model. This step ensures the labels are properly formatted for multi-class classification."]},{"cell_type":"code","execution_count":null,"id":"069c05ad-1743-475a-96bc-6fd79808db45","metadata":{"id":"069c05ad-1743-475a-96bc-6fd79808db45"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","# Initialize the Sequential model\n","model = Sequential()\n","\n","# Input layer\n","model.add(Dense(128, input_dim=10, activation='relu'))  # input_dim matches X_train.shape[1]\n","model.add(Dropout(0.3))\n","\n","# Hidden layers\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","# Output layer\n","num_classes = y_train_one_hot.shape[1]  # Number of unique classes\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Summary\n","model.summary()\n"]},{"cell_type":"markdown","id":"kUyb_naZKZZv","metadata":{"id":"kUyb_naZKZZv"},"source":["\"A sequential deep learning model was designed with an input layer matching the feature dimensions, two hidden layers using ReLU activation for non-linearity, and a softmax output layer for multi-class classification. Dropout layers were added to prevent overfitting, and the model was compiled with categorical cross-entropy loss and accuracy as the evaluation metric."]},{"cell_type":"code","execution_count":null,"id":"db04ccf6-5817-457d-bc7e-d7420e96590c","metadata":{"colab":{"background_save":true},"id":"db04ccf6-5817-457d-bc7e-d7420e96590c"},"outputs":[],"source":["# Train the model\n","history = model.fit(\n","    X_train, y_train_one_hot,  # Features and one-hot encoded labels\n","    validation_data=(X_test, y_test_one_hot),  # Validation data\n","    epochs=20,  # Adjust as needed\n","    batch_size=32,  # Adjust based on dataset size\n","    verbose=1  # Shows training progress\n",")\n"]},{"cell_type":"markdown","id":"LZ7U-t-dKkg7","metadata":{"id":"LZ7U-t-dKkg7"},"source":["The model was trained over 20 epochs using the training dataset, with validation data to monitor performance. Despite completing the training process, the accuracy and loss metrics remained constant across all epochs, indicating the model failed to learn effectively. This could be due to reasons such as insufficient training, poor feature representation, or inappropriate model architecture. Further analysis and adjustments are needed to improve learning outcomes."]},{"cell_type":"code","execution_count":null,"id":"5ac6617a-e6ab-4bf5-b4b5-e2055e418ded","metadata":{"id":"5ac6617a-e6ab-4bf5-b4b5-e2055e418ded"},"outputs":[],"source":["# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test_one_hot, verbose=0)\n","print(f\"Test Loss: {loss:.4f}\")\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"]},{"cell_type":"markdown","id":"bKl889G7K10E","metadata":{"id":"bKl889G7K10E"},"source":["The model evaluation on the test dataset yielded a loss of 4.5752 and a test accuracy of 1.00%. The extremely low accuracy indicates the model failed to generalize or learn meaningful patterns, likely due to issues such as an inappropriate model structure, lack of feature representation, or data-related challenges like imbalance or noise. Further refinement of the model and dataset preprocessing is required"]},{"cell_type":"code","execution_count":null,"id":"b47dadae-90f9-40ad-802d-86cb28aca51c","metadata":{"id":"b47dadae-90f9-40ad-802d-86cb28aca51c"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Plot training and validation accuracy\n","plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Model Accuracy')\n","plt.legend()\n","plt.show()\n","\n","# Plot training and validation loss\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Model Loss')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"markdown","id":"nLAB0FU-LADE","metadata":{"id":"nLAB0FU-LADE"},"source":["The plots of model accuracy and loss over 20 epochs reveal that the model failed to improve its performance. Both training and validation accuracy remained nearly constant at a very low value, indicating a lack of learning. Similarly, the loss metrics show no significant reduction, suggesting issues such as insufficient model complexity, data preprocessing errors, or ineffective feature representation. These results emphasize the need for revising the model architecture and preprocessing steps to enable effective learning."]},{"cell_type":"code","execution_count":null,"id":"c9921104-873a-43d8-9134-a18402912fe7","metadata":{"id":"c9921104-873a-43d8-9134-a18402912fe7"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure(figsize=(12, 10))\n","sns.heatmap(conf_matrix_limited, annot=True, fmt='d', cmap='Blues', cbar=True)\n","\n","plt.title('Confusion Matrix for Top Classes')\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","\n","# Add class names if available\n","class_labels = label_encoder.classes_[:top_classes]  # Assuming label_encoder was used\n","plt.xticks(ticks=np.arange(top_classes) + 0.5, labels=class_labels, rotation=45)\n","plt.yticks(ticks=np.arange(top_classes) + 0.5, labels=class_labels, rotation=45)\n","\n","plt.show()\n"]},{"cell_type":"markdown","id":"pARp3YNHOMyI","metadata":{"id":"pARp3YNHOMyI"},"source":["The confusion matrix presented is ineffective, as it contains only zeros, indicating no valid predictions or classifications were captured. This could result from mismatched or incorrect y_true and y_pred inputs, improper slicing, or errors in the prediction or visualization process. To address this, it is crucial to verify the alignment and correctness of the true and predicted labels, recalibrate the confusion matrix, and ensure meaningful data is processed before visualizing the results."]},{"cell_type":"code","execution_count":null,"id":"2d8103a1-5c33-4546-9ddf-f29f5c2d4728","metadata":{"id":"2d8103a1-5c33-4546-9ddf-f29f5c2d4728"},"outputs":[],"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","# Compute class weights\n","class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(y_train_encoded),\n","    y=y_train_encoded\n",")\n","\n","class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","print(\"Class Weights:\", class_weights_dict)\n"]},{"cell_type":"markdown","id":"GUkzr3ddLZdq","metadata":{"id":"GUkzr3ddLZdq"},"source":["Class weights were computed using compute_class_weight to address class imbalance in the dataset. These weights assign higher importance to underrepresented classes and lower importance to overrepresented ones, helping the model learn more effectively from imbalanced data. The resulting dictionary (class_weights_dict) was used during model training to improve performance across all classes."]},{"cell_type":"code","execution_count":null,"id":"699e291d-77b9-4c90-a8bb-ca115de898a0","metadata":{"id":"699e291d-77b9-4c90-a8bb-ca115de898a0"},"outputs":[],"source":["model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy'],\n","    weighted_metrics=class_weights_dict  # Pass the class weights\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"c0327b06-c1c6-4e55-af31-72bf8a203d5f","metadata":{"id":"c0327b06-c1c6-4e55-af31-72bf8a203d5f"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Plot training and validation accuracy\n","plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"markdown","id":"TQQaFkNtLnLH","metadata":{"id":"TQQaFkNtLnLH"},"source":["The training and validation accuracy plot shows significant fluctuations without meaningful improvement over epochs. This indicates that the model struggles to learn patterns from the data, likely due to factors like an ineffective model architecture, insufficient feature representation, or noisy data. The lack of convergence suggests the need for deeper analysis and adjustments in the model or data preprocessing."]},{"cell_type":"code","execution_count":null,"id":"25c67722-55ee-4e06-9c2b-e6c9e046c5a6","metadata":{"id":"25c67722-55ee-4e06-9c2b-e6c9e046c5a6"},"outputs":[],"source":["for i in range(10):  # Display 10 test samples\n","    print(f\"True Label: {y_true_classes[i]}, Predicted Label: {y_pred_classes[i]}\")\n"]},{"cell_type":"code","execution_count":null,"id":"e309b6f3-6b59-44b9-93bb-00009ac6a9b3","metadata":{"id":"e309b6f3-6b59-44b9-93bb-00009ac6a9b3"},"outputs":[],"source":["print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n","print(f\"Class distribution after SMOTE: {np.bincount(y_train_encoded)}\")\n"]},{"cell_type":"code","execution_count":null,"id":"b6415ac3-1359-400f-b8f9-837ce6258be7","metadata":{"id":"b6415ac3-1359-400f-b8f9-837ce6258be7"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n"]},{"cell_type":"code","execution_count":null,"id":"74d89efa-1be1-4c0c-9123-fb79af9f7d1a","metadata":{"id":"74d89efa-1be1-4c0c-9123-fb79af9f7d1a"},"outputs":[],"source":["model = Sequential()\n","model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))  # Ensure output matches number of classes\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"]},{"cell_type":"markdown","id":"DEeGlAMxMJhP","metadata":{"id":"DEeGlAMxMJhP"},"source":["In this section, the predicted test labels revealed a single dominant class (76), indicating poor model generalization. To address this, SMOTE was used to balance the class distribution, ensuring equal representation across all classes. Features were standardized using StandardScaler for improved training stability. A new Sequential model was implemented with additional layers, dropout for regularization, and a softmax output layer, aiming to improve multi-class classification performance."]},{"cell_type":"code","execution_count":null,"id":"1b15f5b3-2590-47e4-a0fd-f3987f642846","metadata":{"id":"1b15f5b3-2590-47e4-a0fd-f3987f642846"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","optimizer = Adam(learning_rate=0.0001)  # Smaller learning rate\n","model.compile(\n","    optimizer=optimizer,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"9803e201-abad-483a-bef6-be493f11207e","metadata":{"id":"9803e201-abad-483a-bef6-be493f11207e"},"outputs":[],"source":["history = model.fit(\n","    X_train, y_train_one_hot,\n","    validation_data=(X_test, y_test_one_hot),\n","    epochs=50,\n","    batch_size=32\n",")\n"]},{"cell_type":"markdown","id":"dq2rPl14MbAX","metadata":{"id":"dq2rPl14MbAX"},"source":["The model was trained for 50 epochs, showing consistent improvement in both training and validation accuracy, with the validation accuracy reaching around 83.9%. The loss values steadily decreased, indicating effective learning and convergence. This reflects that the new architecture and preprocessing steps, including SMOTE and scaling, contributed to improved model performance."]},{"cell_type":"code","execution_count":null,"id":"27d244be-ab95-4986-baea-b968a4177204","metadata":{"id":"27d244be-ab95-4986-baea-b968a4177204"},"outputs":[],"source":["model.save('trained_model.keras')\n"]},{"cell_type":"code","execution_count":null,"id":"02a82d5e-cd3f-48d5-96aa-0f0629e27bc3","metadata":{"id":"02a82d5e-cd3f-48d5-96aa-0f0629e27bc3"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","loaded_model = load_model('trained_model.keras')\n"]},{"cell_type":"code","execution_count":null,"id":"8b424f6f-f736-4bc9-a8d3-d64195710a8c","metadata":{"id":"8b424f6f-f736-4bc9-a8d3-d64195710a8c"},"outputs":[],"source":["# Evaluate the loaded model\n","loss, accuracy = loaded_model.evaluate(X_test, y_test_one_hot, verbose=0)\n","print(f\"Test Loss: {loss:.4f}\")\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"]},{"cell_type":"code","execution_count":null,"id":"be32ce18-3012-4ea8-b31f-b440283ed167","metadata":{"id":"be32ce18-3012-4ea8-b31f-b440283ed167"},"outputs":[],"source":["# Predict using the loaded model\n","y_pred = loaded_model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","# Display some predictions\n","for i in range(5):\n","    print(f\"Sample {i+1}: True Label = {y_true_classes[i]}, Predicted Label = {y_pred_classes[i]}\")\n"]},{"cell_type":"markdown","id":"Wxil4QD4Mop4","metadata":{"id":"Wxil4QD4Mop4"},"source":["Predictions were generated using the trained model on the test set. A sample of predictions shows that the model successfully predicted the correct labels for several test samples, indicating that the model has learned meaningful patterns and improved in its classification performance compared to earlier iterations."]},{"cell_type":"code","execution_count":null,"id":"3f4cfe9c-4365-40a8-9f94-1a1988f2bb79","metadata":{"id":"3f4cfe9c-4365-40a8-9f94-1a1988f2bb79"},"outputs":[],"source":["import numpy as np\n","\n","# Find top N classes with the highest support\n","top_classes = 10\n","class_support = np.sum(conf_matrix, axis=1)\n","top_class_indices = np.argsort(class_support)[-top_classes:]\n","\n","# Slice the confusion matrix\n","conf_matrix_limited = conf_matrix[np.ix_(top_class_indices, top_class_indices)]\n","\n","# Plot the confusion matrix for top classes\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix_limited, annot=True, fmt='d', cmap='Blues', cbar=True)\n","\n","# Add class labels\n","plt.title(f'Confusion Matrix (Top {top_classes} Classes)')\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.xticks(ticks=np.arange(top_classes) + 0.5, labels=top_class_indices, rotation=45)\n","plt.yticks(ticks=np.arange(top_classes) + 0.5, labels=top_class_indices, rotation=45)\n","plt.show()\n"]},{"cell_type":"markdown","id":"Rw2qCZmcM1iN","metadata":{"id":"Rw2qCZmcM1iN"},"source":["A confusion matrix was generated for the top 10 most frequent classes to visualize the model's performance. The diagonal dominance indicates that the model accurately predicted the majority of samples for these classes. This focused analysis highlights the model's effectiveness in handling the most common classes while providing insights into potential misclassifications for further refinement."]},{"cell_type":"markdown","id":"8qwST8XaPCgK","metadata":{"id":"8qwST8XaPCgK"},"source":["# Insights for LAPD from Crime Prediction Model"]},{"cell_type":"code","execution_count":null,"id":"901ce25f-58e6-4f7e-b1db-4fe191ce52dc","metadata":{"id":"901ce25f-58e6-4f7e-b1db-4fe191ce52dc"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0903048c-e370-4384-aa58-11ea68ae3e66","metadata":{"id":"0903048c-e370-4384-aa58-11ea68ae3e66"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"834b84fa-fcbb-4770-ab02-e3b0caecee61","metadata":{"id":"834b84fa-fcbb-4770-ab02-e3b0caecee61"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9bbb95e1-49d2-4970-932e-207d017e2374","metadata":{"id":"9bbb95e1-49d2-4970-932e-207d017e2374"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"06449097-35e4-4f93-817e-00bf9e02631e","metadata":{"id":"06449097-35e4-4f93-817e-00bf9e02631e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"308a0158-f380-4d80-a5da-91c33040bce6","metadata":{"id":"308a0158-f380-4d80-a5da-91c33040bce6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"36ec7edc-2795-4631-a6f3-c3fb552e02f8","metadata":{"id":"36ec7edc-2795-4631-a6f3-c3fb552e02f8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"dfaf2227-e229-4635-9976-7cd8e65a49e9","metadata":{"id":"dfaf2227-e229-4635-9976-7cd8e65a49e9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6f1a0464-99e0-4659-a825-be1efbf1752a","metadata":{"id":"6f1a0464-99e0-4659-a825-be1efbf1752a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"86755490-c6b1-4b71-bc83-b08ce3e82f47","metadata":{"id":"86755490-c6b1-4b71-bc83-b08ce3e82f47"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"86773efe-f149-4f56-9681-7d0518553ec5","metadata":{"id":"86773efe-f149-4f56-9681-7d0518553ec5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0defcd03-e68c-47c2-b4f5-3540e0157305","metadata":{"id":"0defcd03-e68c-47c2-b4f5-3540e0157305"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"dc53e7c2-614a-4a78-bd9a-a22f1ad41452","metadata":{"id":"dc53e7c2-614a-4a78-bd9a-a22f1ad41452"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fc77a9ee-fa01-49d4-9e68-baaec64f8e21","metadata":{"id":"fc77a9ee-fa01-49d4-9e68-baaec64f8e21"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fad5e3aa-c310-48dc-ad10-6f763893a231","metadata":{"id":"fad5e3aa-c310-48dc-ad10-6f763893a231"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"3a986fdd-4302-40d8-ba24-26e8cf7af15d","metadata":{"id":"3a986fdd-4302-40d8-ba24-26e8cf7af15d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e8fa6a2b-00d8-4046-9728-c7332339f119","metadata":{"id":"e8fa6a2b-00d8-4046-9728-c7332339f119"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9ae35f9c-be85-4182-838b-a2e03fa0894e","metadata":{"id":"9ae35f9c-be85-4182-838b-a2e03fa0894e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d87a6b79-35c0-44ab-ad19-c76f02c8dab3","metadata":{"id":"d87a6b79-35c0-44ab-ad19-c76f02c8dab3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5147d281-8fa4-41d6-a2b6-db20ecd5509a","metadata":{"id":"5147d281-8fa4-41d6-a2b6-db20ecd5509a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"310d2bcc-f9d0-40af-8c61-a1a91be4d0c0","metadata":{"id":"310d2bcc-f9d0-40af-8c61-a1a91be4d0c0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d170407f-0b7d-462e-9d3d-9489e74ccb7c","metadata":{"id":"d170407f-0b7d-462e-9d3d-9489e74ccb7c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"746c2b45-fd45-4ce7-954d-60725f216564","metadata":{"id":"746c2b45-fd45-4ce7-954d-60725f216564"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5dcb9f0a-586c-49fe-bd70-54c0c2c74ba2","metadata":{"id":"5dcb9f0a-586c-49fe-bd70-54c0c2c74ba2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"79b589f6-485e-40e9-8ab2-89e46148acd6","metadata":{"id":"79b589f6-485e-40e9-8ab2-89e46148acd6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"cea5c47a-6a2e-4475-ae38-8a9edd0d50c6","metadata":{"id":"cea5c47a-6a2e-4475-ae38-8a9edd0d50c6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"44bec3c0-2215-44ad-81ce-cf537700a08c","metadata":{"id":"44bec3c0-2215-44ad-81ce-cf537700a08c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"36895b07-f4fd-482a-9a03-02c03e2a9d5b","metadata":{"id":"36895b07-f4fd-482a-9a03-02c03e2a9d5b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0929450d-7910-4f7b-9354-1647186652b0","metadata":{"id":"0929450d-7910-4f7b-9354-1647186652b0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4a2cd494-b5c6-423c-b9bb-de1ebba79b91","metadata":{"id":"4a2cd494-b5c6-423c-b9bb-de1ebba79b91"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"c9928500-21a7-4e7f-b509-65dbaf577942","metadata":{"id":"c9928500-21a7-4e7f-b509-65dbaf577942"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"c72f16ce-77f3-4ff6-a43c-bcf5b57ea763","metadata":{"id":"c72f16ce-77f3-4ff6-a43c-bcf5b57ea763"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}